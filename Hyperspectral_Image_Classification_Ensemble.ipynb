{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PowerTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "INPUT_ROOT = '../input'\n",
    "directories = os.listdir(INPUT_ROOT)\n",
    "if len(directories) > 0:\n",
    "    BASE_PATH = os.path.join(INPUT_ROOT, directories[0]) \n",
    "else:\n",
    "    BASE_PATH = '../input'\n",
    "\n",
    "if os.path.exists(os.path.join(BASE_PATH, 'dataset')):\n",
    "    BASE_PATH = os.path.join(BASE_PATH, 'dataset')\n",
    "\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_PATH, 'train')\n",
    "TEST_IMG_DIR = os.path.join(BASE_PATH, 'test')\n",
    "\n",
    "\n",
    "possible_labels = ['train.csv', 'labels.csv', 'train_labels.csv']\n",
    "LABELS_FILE = None\n",
    "for f in possible_labels:\n",
    "    path = os.path.join(BASE_PATH, f)\n",
    "    if os.path.exists(path):\n",
    "        LABELS_FILE = path\n",
    "        break\n",
    "\n",
    "N_FOLDS = 10\n",
    "BATCH_SIZE = 128\n",
    "CONFIDENCE_THRESHOLD = 0.95  #\n",
    "\n",
    "\n",
    "def extract_features(dataframe, folder):\n",
    "    features = []\n",
    "    labels = []\n",
    "    c = 9\n",
    "    \n",
    "    for idx, row in dataframe.iterrows():\n",
    "        try:\n",
    "            path = os.path.join(folder, row['filename'])\n",
    "            img = np.load(path) \n",
    "            \n",
    "          \n",
    "            center = img[c, c, :]\n",
    "            \n",
    "            \n",
    "            d1 = np.diff(center)\n",
    "            d2 = np.diff(d1)\n",
    "            \n",
    "            \n",
    "            neighbors = img[c-1:c+2, c-1:c+2, :]\n",
    "            n_mean = np.mean(neighbors, axis=(0, 1))\n",
    "            n_std = np.std(neighbors, axis=(0, 1))\n",
    "            \n",
    "           \n",
    "            skew = np.mean((center - np.mean(center))**3)\n",
    "            kurt = np.mean((center - np.mean(center))**4)\n",
    "            area = np.trapz(center)\n",
    "            \n",
    "            \n",
    "            ratio_ir_blue = (center[-1] - center[0]) / (center[-1] + center[0] + 1e-6)\n",
    "            \n",
    "            feat = np.concatenate([\n",
    "                center, d1, d2, n_mean, n_std, [skew, kurt, area, ratio_ir_blue]\n",
    "            ])\n",
    "            \n",
    "            features.append(feat)\n",
    "            if 'label' in row:\n",
    "                labels.append(row['label'])\n",
    "            else:\n",
    "                labels.append(0)\n",
    "        except:\n",
    "            pass\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "print(\">>> [1/5] Încărcare și procesare date...\")\n",
    "df = pd.read_csv(LABELS_FILE)\n",
    "df_filtered = df[~df['label'].isin([4, 5])].copy()\n",
    "\n",
    "X_train_orig, y_train_orig = extract_features(df_filtered, TRAIN_IMG_DIR)\n",
    "\n",
    "test_files = sorted([f for f in os.listdir(TEST_IMG_DIR) if f.endswith('.npy')])\n",
    "df_test = pd.DataFrame({'filename': test_files})\n",
    "X_test, _ = extract_features(df_test, TEST_IMG_DIR)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_orig)\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "\n",
    "\n",
    "print(\">>> [2/5] Scalare date (PowerTransformer)...\")\n",
    "scaler = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_orig)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "def train_lgbm(X, y, X_test_curr):\n",
    "    \"\"\" Antrenează LightGBM și returnează probabilitățile pe Test \"\"\"\n",
    "    probs = np.zeros((len(X_test_curr), NUM_CLASSES))\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (t_idx, v_idx) in enumerate(skf.split(X, y)):\n",
    "        X_t, X_v = X[t_idx], X[v_idx]\n",
    "        y_t, y_v = y[t_idx], y[v_idx]\n",
    "        \n",
    "        clf = lgb.LGBMClassifier(\n",
    "            n_estimators=1500, learning_rate=0.03, num_leaves=31,\n",
    "            subsample=0.8, colsample_bytree=0.7, class_weight='balanced',\n",
    "            device='gpu', verbose=-1\n",
    "        )\n",
    "        clf.fit(X_t, y_t, eval_set=[(X_v, y_v)])\n",
    "        probs += clf.predict_proba(X_test_curr)\n",
    "        \n",
    "    return probs / N_FOLDS\n",
    "\n",
    "def build_mlp(input_dim):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(512, kernel_initializer='he_normal'), BatchNormalization(), Activation('relu'), Dropout(0.4),\n",
    "        Dense(256, kernel_initializer='he_normal'), BatchNormalization(), Activation('relu'), Dropout(0.3),\n",
    "        Dense(128, kernel_initializer='he_normal'), BatchNormalization(), Activation('relu'), Dropout(0.2),\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_mlp(X, y, X_test_curr):\n",
    "    \"\"\" Antrenează MLP și returnează probabilitățile pe Test \"\"\"\n",
    "    probs = np.zeros((len(X_test_curr), NUM_CLASSES))\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (t_idx, v_idx) in enumerate(skf.split(X, y)):\n",
    "        X_t, X_v = X[t_idx], X[v_idx]\n",
    "        y_t, y_v = y[t_idx], y[v_idx]\n",
    "        \n",
    "        model = build_mlp(X.shape[1])\n",
    "        callbacks = [\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=0),\n",
    "            EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)\n",
    "        ]\n",
    "        \n",
    "        model.fit(X_t, y_t, epochs=80, batch_size=BATCH_SIZE, \n",
    "                  validation_data=(X_v, y_v), callbacks=callbacks, verbose=0)\n",
    "        \n",
    "        probs += model.predict(X_test_curr, batch_size=BATCH_SIZE, verbose=0)\n",
    "        \n",
    "    return probs / N_FOLDS\n",
    "\n",
    "\n",
    "print(\"\\n>>> [3/5] ETAPA 1: Antrenare pe datele originale...\")\n",
    "p_lgbm_1 = train_lgbm(X_train_orig, y_train_encoded, X_test) \n",
    "p_mlp_1 = train_mlp(X_train_scaled, y_train_encoded, X_test_scaled) \n",
    "\n",
    "\n",
    "preds_stage1 = (0.4 * p_lgbm_1) + (0.6 * p_mlp_1)\n",
    "\n",
    "\n",
    "print(f\"\\n>>> [4/5] ETAPA 2: Pseudo-Labeling (Prag: {CONFIDENCE_THRESHOLD*100}%)\")\n",
    "\n",
    "\n",
    "max_p = np.max(preds_stage1, axis=1)\n",
    "pseudo_labels = np.argmax(preds_stage1, axis=1)\n",
    "\n",
    "high_conf_idx = np.where(max_p >= CONFIDENCE_THRESHOLD)[0]\n",
    "print(f\" -> Din {len(X_test)} exemple test, adăugăm {len(high_conf_idx)} în Train.\")\n",
    "\n",
    "\n",
    "X_pseudo_orig = X_test[high_conf_idx]\n",
    "X_pseudo_scaled = X_test_scaled[high_conf_idx]\n",
    "y_pseudo = pseudo_labels[high_conf_idx]\n",
    "\n",
    "\n",
    "X_train_aug_orig = np.concatenate([X_train_orig, X_pseudo_orig], axis=0)\n",
    "X_train_aug_scaled = np.concatenate([X_train_scaled, X_pseudo_scaled], axis=0)\n",
    "y_train_aug = np.concatenate([y_train_encoded, y_pseudo], axis=0)\n",
    "\n",
    "\n",
    "print(\" -> Re-antrenare LightGBM pe setul extins...\")\n",
    "p_lgbm_2 = train_lgbm(X_train_aug_orig, y_train_aug, X_test)\n",
    "\n",
    "print(\" -> Re-antrenare MLP pe setul extins...\")\n",
    "p_mlp_2 = train_mlp(X_train_aug_scaled, y_train_aug, X_test_scaled)\n",
    "\n",
    "\n",
    "print(\"\\n>>> [5/5] Finalizare...\")\n",
    "\n",
    "final_probs = (0.4 * p_lgbm_2) + (0.6 * p_mlp_2)\n",
    "\n",
    "final_preds_idx = np.argmax(final_probs, axis=1)\n",
    "final_preds_label = le.inverse_transform(final_preds_idx)\n",
    "\n",
    "\n",
    "unique, counts = np.unique(final_preds_label, return_counts=True)\n",
    "print(f\"Distribuția Finală: {dict(zip(unique, counts))}\")\n",
    "\n",
    "submission = pd.DataFrame({'filename': test_files, 'label': final_preds_label})\n",
    "submission.to_csv('submission_pseudo_labeling_85.csv', index=False)\n",
    "print(\">>> GATA! 'submission_pseudo_labeling_85.csv' este gata.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14740007,
     "sourceId": 124990,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
